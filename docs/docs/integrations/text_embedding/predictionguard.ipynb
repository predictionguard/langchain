{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PredictionGuardEmbeddings"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ">[Prediction Guard](https://predictionguard.com) is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overview"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Integration details\n",
    "This integration shows how to use the Prediction Guard embeddings integration with Langchain. This integration supports text and images, separately or together in matched pairs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "To access Prediction Guard models, contact us [here](https://predictionguard.com/get-started) to get a Prediction Guard API key and get started. \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Credentials\n",
    "Once you have a key, you can set it with \n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:59:10.422135Z",
     "start_time": "2024-10-08T18:59:10.419563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PREDICTIONGUARD_API_KEY\"] = \"<Prediction Guard API Key>\""
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Installation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install --upgrade --quiet predictionguard langchain"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Instantiation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, install the Prediction Guard and LangChain packages. Then, set the required env vars and set up package imports."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:13:40.463622Z",
     "start_time": "2024-10-08T18:13:40.240249Z"
    }
   },
   "source": "from langchain_community.embeddings.predictionguard import PredictionGuardEmbeddings",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:14:14.324100Z",
     "start_time": "2024-10-08T18:14:13.997521Z"
    }
   },
   "source": [
    "embeddings = PredictionGuardEmbeddings(model=\"bridgetower-large-itm-mlm-itc\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Guard embeddings generation supports both text and images. This integration includes that support spread across various functions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Indexing and Retrieval"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:14:29.307881Z",
     "start_time": "2024-10-08T18:14:28.405099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a vector store with a sample text\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications.\"\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use the vectorstore as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "# Show the retrieved document's content\n",
    "retrieved_documents[0].page_content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is the framework for building context-aware reasoning applications.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Direct Usage\n",
    "The vectorstore and retriever implementations are calling `embeddings.embed_documents(...)` and `embeddings.embed_query(...)` to create embeddings from the texts used in the `from_texts` and retrieval `invoke` operations.\n",
    "\n",
    "These methods can be directly called with the following commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single texts"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:16:00.824334Z",
     "start_time": "2024-10-08T18:16:00.368665Z"
    }
   },
   "source": [
    "# Embedding a single string\n",
    "text = \"This is an embedding example.\"\n",
    "single_vector = embeddings.embed_query(text)\n",
    "\n",
    "single_vector[:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01456777285784483,\n",
       " -0.08131945133209229,\n",
       " -0.013045587576925755,\n",
       " -0.09488929063081741,\n",
       " -0.003087474964559078]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple texts"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:16:11.076843Z",
     "start_time": "2024-10-08T18:16:10.655925Z"
    }
   },
   "source": [
    "# Embedding multiple strings\n",
    "docs = [\n",
    "    \"This is an embedding example.\",\n",
    "    \"This is another embedding example.\",\n",
    "]\n",
    "\n",
    "two_vectors = embeddings.embed_documents(docs)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01456777285784483, -0.08131945133209229, -0.013045587576925755, -0.09488929063081741, -0.003087474964559078]\n",
      "[-0.0015021917643025517, -0.08883760124444962, -0.0025286630261689425, -0.1052245944738388, 0.014225339516997337]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single images"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:16:44.853569Z",
     "start_time": "2024-10-08T18:16:43.457282Z"
    }
   },
   "source": [
    "# Embedding a single image. These functions accept image URLs, image files, data URIs, and base64 encoded strings.\n",
    "image = [\n",
    "    \"https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png\",\n",
    "]\n",
    "single_vector = embeddings.embed_images(image)\n",
    "\n",
    "print(single_vector[0][:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06482088565826416, -0.026690427213907242, 0.07683052867650986, -0.060580912977457047, 0.0001994583144551143]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple images"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:17:02.165077Z",
     "start_time": "2024-10-08T18:17:00.612485Z"
    }
   },
   "source": [
    "# Embedding multiple images\n",
    "images = [\n",
    "    \"https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png\",\n",
    "    \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "]\n",
    "\n",
    "two_vectors = embeddings.embed_images(images)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06482088565826416, -0.026690427213907242, 0.07683052867650986, -0.060580912977457047, 0.0001994583144551143]\n",
      "[0.0911610797047615, -0.034427884966135025, 0.007927080616354942, -0.03500846028327942, 0.022317267954349518]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single text-image pairs"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:17:17.113169Z",
     "start_time": "2024-10-08T18:17:15.669474Z"
    }
   },
   "source": [
    "# Embedding a single text-image pair\n",
    "inputs = [\n",
    "    {\n",
    "        \"text\": \"This is an embedding example.\",\n",
    "        \"image\": \"https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png\",\n",
    "    },\n",
    "]\n",
    "single_vector = embeddings.embed_image_text(inputs)\n",
    "\n",
    "print(single_vector[0][:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025471875444054604, -0.07661919295787811, 0.06256384402513504, -0.06042419373989105, 0.016889123246073723]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple text-image pairs"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:17:31.948434Z",
     "start_time": "2024-10-08T18:17:30.393415Z"
    }
   },
   "source": [
    "# Embedding multiple text-image pairs\n",
    "inputs = [\n",
    "    {\n",
    "        \"text\": \"This is an embedding example.\",\n",
    "        \"image\": \"https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This is another embedding example.\",\n",
    "        \"image\": \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "    },\n",
    "]\n",
    "two_vectors = embeddings.embed_image_text(inputs)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025471875444054604, -0.07661919295787811, 0.06256384402513504, -0.06042419373989105, 0.016889123246073723]\n",
      "[0.026654226705431938, -0.10080841928720474, -0.012732953764498234, -0.04365091398358345, 0.036743905395269394]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## API Reference\n",
    "For detailed documentation of all PredictionGuardEmbeddings features and configurations check out the API reference: https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.predictionguard.PredictionGuardEmbeddings.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
